{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2065403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e67494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 加载和准备数据\n",
    "data = pd.read_csv('earthquake.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S').dt.time\n",
    "data['Timestamp'] = data.apply(lambda row: pd.Timestamp(f\"{row['Date']} {row['Time']}\"), axis=1)\n",
    "data['Timestamp'] = data['Timestamp'].view('int64') // 10**9 #Unix时间戳\n",
    "features = data[['Timestamp', 'Longitude', 'Latitude']]\n",
    "targets = data[['Depth', 'Magnitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f798d71-1fa5-4e84-8fb4-bf15b30413cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np=features.values\n",
    "y_np=targets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f55c73b-a92a-4194-9944-f4e766459d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_x.fit(X_np)\n",
    "scaler_y.fit(y_np)\n",
    "\n",
    "# 使用相同的参数对训练数据和测试数据进行归一化\n",
    "X_normalized = scaler_x.transform(X_np)\n",
    "y_normalized = scaler_y.transform(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6136a67-3a5b-415d-8d10-4a942d6e9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(X, Y, window_size):\n",
    "    X_windows, Y_windows = [], []\n",
    "    for i in range(len(X) - window_size):\n",
    "        # 从X中提取窗口\n",
    "        X_window = X[i:i+window_size]\n",
    "        # 从Y中提取紧接着窗口的下一个值作为标签\n",
    "        Y_window = Y[i+window_size]\n",
    "        X_windows.append(X_window)\n",
    "        Y_windows.append(Y_window)\n",
    "    return np.array(X_windows), np.array(Y_windows)\n",
    "\n",
    "window_size = 20\n",
    "X_windows, Y_windows = create_sliding_windows(X_normalized, y_normalized, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3a0dac-015d-4c36-a55d-a105c5e833dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X_windows, dtype=torch.float32)\n",
    "Y = torch.tensor(Y_windows, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7759d3-cebf-4095-a004-6e3cf248b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定测试集的大小\n",
    "test_size = 0.2\n",
    "\n",
    "# 计算测试集应有的数据点数量\n",
    "num_data_points = len(X)\n",
    "num_test_points = int(num_data_points * test_size)\n",
    "\n",
    "# 计算测试集和训练集的分割点\n",
    "split_point = num_data_points - num_test_points\n",
    "\n",
    "# 按顺序划分数据为训练集和测试集\n",
    "X_train = X[:split_point]\n",
    "X_test = X[split_point:]\n",
    "y_train = Y[:split_point]\n",
    "y_test = Y[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671d7c6c-7c06-4414-889d-5c27345f68c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18714, 20, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98436c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建DataLoader\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e47110-907c-4e08-8525-39ff6156453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85747939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# 定义Transformer模型\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len, hidden_dim, output_dim, num_layers, dropout_prob):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.pos_encoder = PositionalEncoding(hidden_dim, dropout_prob)\n",
    "\n",
    "        # 由于3是质数，我们可以选择将输入特征投影到更高的维度\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(d_model=hidden_dim, nhead=8, \n",
    "                                                 dim_feedforward=hidden_dim, dropout=dropout_prob)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer=encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # 将输入特征投影到更高的维度\n",
    "        x = self.dropout(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.permute(1, 0, 2)  # Transformer expects (Seq Len, Batch, Features)\n",
    "        out = self.transformer_encoder(x)\n",
    "        out = self.fc_out(out[-1, :, :])  # 取最后一个时间步\n",
    "        return out\n",
    "\n",
    "# 初始化模型参数\n",
    "input_dim = 3  # 时间、经度、纬度\n",
    "seq_len = 20   # 序列长度\n",
    "hidden_dim = 64  # 隐藏层的维度\n",
    "num_layers = 2  # Transformer层的数量\n",
    "output_dim = 2  # 震深和震级\n",
    "dropout_prob = 0.5  # Dropout概率\n",
    "\n",
    "# 创建模型\n",
    "model = TransformerModel(input_dim, seq_len, hidden_dim, output_dim, num_layers, dropout_prob)\n",
    "\n",
    "# 检查CUDA是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 将模型移到GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()  # 因为是回归问题\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 设置训练轮数\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77d559d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.0226\n",
      "Epoch [20/200], Loss: 0.0225\n",
      "Epoch [30/200], Loss: 0.0225\n",
      "Epoch [40/200], Loss: 0.0224\n",
      "Epoch [50/200], Loss: 0.0223\n",
      "Epoch [60/200], Loss: 0.0223\n",
      "Epoch [70/200], Loss: 0.0223\n",
      "Epoch [80/200], Loss: 0.0223\n",
      "Epoch [90/200], Loss: 0.0223\n",
      "Epoch [100/200], Loss: 0.0222\n",
      "Epoch [110/200], Loss: 0.0222\n",
      "Epoch [120/200], Loss: 0.0222\n",
      "Epoch [130/200], Loss: 0.0222\n",
      "Epoch [140/200], Loss: 0.0222\n",
      "Epoch [150/200], Loss: 0.0222\n",
      "Epoch [160/200], Loss: 0.0222\n",
      "Epoch [170/200], Loss: 0.0222\n",
      "Epoch [180/200], Loss: 0.0222\n",
      "Epoch [190/200], Loss: 0.0222\n",
      "Epoch [200/200], Loss: 0.0222\n",
      "Training complete. Best loss: 0.0222\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "best_model_path = 'best_transformer_model.pth'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 确保模型处于训练模式\n",
    "    epoch_loss = 0.0  # 用于累积整个epoch的损失\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # 移动数据到GPU\n",
    "        \n",
    "        optimizer.zero_grad()  # 清除过往梯度\n",
    "        \n",
    "        outputs = model(inputs)  # 前向传播\n",
    "        \n",
    "        loss = criterion(outputs, targets)  # 计算损失\n",
    "        loss.backward()  # 后向传播，计算梯度\n",
    "        optimizer.step()  # 更新权重\n",
    "\n",
    "        epoch_loss += loss.item() * inputs.size(0)  # 累积损失\n",
    "\n",
    "    # 计算整个epoch的平均损失\n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # 打印训练进度\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "torch.save(model.state_dict(), 'last_transformer_model.pth')\n",
    "\n",
    "print(\"Training complete. Best loss: {:.4f}\".format(best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e35aad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval() # 将模型设置为评估模式\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad(): # 不计算梯度\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device) # 移动数据到GPU\n",
    "            outputs = model(inputs)\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "            actuals.append(targets.cpu().numpy())\n",
    "    \n",
    "    predictions = np.vstack(predictions)\n",
    "    actuals = np.vstack(actuals)\n",
    "    \n",
    "    # 反标准化以比较实际值\n",
    "    predictions = scaler_y.inverse_transform(predictions)\n",
    "    actuals = scaler_y.inverse_transform(actuals)\n",
    "    \n",
    "    # 计算均方根误差\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # 计算平均绝对误差\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "690d601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 9.594\n",
      "Mean Absolute Error (MAE): 8.762\n"
     ]
    }
   ],
   "source": [
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)  # 确保模型在正确的设备上\n",
    "\n",
    "# 评估模型\n",
    "rmse, mae = evaluate_model(model, test_loader)\n",
    "\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
