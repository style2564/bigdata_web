import streamlit as st
from pathlib import Path
import base64
import pandas as pd
import time

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans



def process_df(df):
    # è¯»å–åœç”¨è¯è¡¨
    stopwords = set()
    with open('C:/Users/Administrator/Desktop/nlpforall/cn_text_classifier_master/static/dict.txt', 'r', encoding='utf-8') as f:
        for word in f:
            stopwords.add(word.strip())
    with open('C:/Users/Administrator/Desktop/nlpforall/cn_text_classifier_master/static/stop_words.txt', 'r', encoding='utf-8') as f:
        for word in f:
            stopwords.add(word.strip())
    with open('C:/Users/Administrator/Desktop/nlpforall/cn_text_classifier_master/static/stopwords.txt', 'r', encoding='utf-8') as f:
        for word in f:
            stopwords.add(word.strip())

    # å®šä¹‰åˆ†è¯å‡½æ•°
    def tokenize(text):
        words = jieba.cut(text)
        return [word for word in words if word not in stopwords]

    # å¯¹ content åˆ—åº”ç”¨åˆ†è¯å‡½æ•°
    df['content'] = df['content'].apply(tokenize)

    return df

def merge_lists_to_string(df):
    ale = []
    for i in df['content']:
        ale.append(" ".join(i))
    df['content'] = ale
    return df

def process_plot(x,y):
    lis = []
    for i in range(len(x)):
        lis1 = []
        for j in range(len(x[i])):
            lis1.append([x[i][j],y[i][j]])
        lis.append(lis1)
    options = {
        "title": {"text": "èšç±»ç»“æœæ•£ç‚¹å›¾"},
        "xAxis": {},
        "yAxis": {},
        "series": []
    }
    colors = ["#FFCC99", "#99CCFF", "#99FF99", "#FF99CC", "#CCCCFF", "#FFFF99", "#FF9999", "#99FFFF", "#CC99FF", "#CCFF99"]
    # éå† data_list ä¸­çš„æ¯ä¸ªå­åˆ—è¡¨ï¼Œä¸ºæ¯ä¸ªå­åˆ—è¡¨åˆ›å»ºä¸€ä¸ª series å¹¶è®¾ç½®é¢œè‰²
    for i, data in enumerate(lis):
        series = {
            "symbolSize": 20,
            "data": data,
            "type": "scatter",
            "itemStyle": {"color": colors[i]}  # è®¾ç½®ä¸åŒçš„é¢œè‰²
        }
        options["series"].append(series)
    with tab4:
        stqdm(time.sleep(13.82))
        st_echarts(options=options, height="500px",width="900px")
    return lis

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="NLP Agent",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        "Get Help": "https://www.example.com/help",
        "Report a bug": "https://www.example.com/bug",
        "About": "This is an **extremely** cool NLP app made by Streamlit. Source code: https://github.com/example/nlp-app",
    },
)

# è·å–é™æ€æ–‡ä»¶å¤¹çš„è·¯å¾„
static_dir = Path(st.__path__[0]) / "static"

# æ„é€ å›¾ç‰‡è·¯å¾„
image_path = static_dir / "image" / "cluser.svg"



# å®šä¹‰ CSS æ ·å¼
css = """
<style>
    .container {
        display: flex;
        flex-direction: row;
        align-items: center;
        justify-content: center;
        padding: 20px;
        background-color: #f0f0f0;
        border-radius: 10px;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.2);
    }

    .title {
        font-size: 36px;
        font-weight: bold;
        color: #333333;
        margin-right: 20px;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
    }

    .image {
        width: 50px;
        height: 50px;
        object-fit: contain;
    }
</style>
"""

# æ„é€  HTML å†…å®¹
html_content = f"""
{css}
<div class="container">
    <h1 class="title">NLP Agent demo3 - æ–‡æœ¬èšç±»</h1>
    <img class="image" src="data:image/svg+xml;base64,{image_data}">
</div>
"""

st.markdown(html_content, unsafe_allow_html=True)

st.divider()

st.sidebar.subheader("æ–‡æœ¬èšç±» ğŸ˜š")
st.sidebar.info("è¿™é‡Œæ˜¯æ–‡æœ¬èšç±»åŠŸèƒ½çš„è¯´æ˜...")

st.sidebar.subheader("é«˜çº§é€‰é¡¹")
model = st.sidebar.radio("ä½ æƒ³ç”¨ä»€ä¹ˆè¡Œä¸šæ¨¡å‹è¿›è¡Œè¯¥ä»»åŠ¡",[":rainbow[Kmeans] :large_orange_diamond:", "***DBSCAN*** :large_orange_diamond:", "Birch :large_orange_diamond:"])

# ä¸Šä¼ CSVæ–‡ä»¶
uploaded_file = st.file_uploader("åœ¨è¿™é‡Œä¸Šä¼ CSVæ–‡ä»¶,æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ–‡æœ¬ä¸ªä½“")
if uploaded_file:
    tab1,tab2,tab3,tab4,tab5 = st.tabs(["åŸå§‹è¡¨æ ¼", "å¤„ç†åè¡¨æ ¼","èšç±»åè¡¨æ ¼", "èšç±»æ•£ç‚¹å›¾","ä¸åŒç°‡çš„ä¸»é¢˜è¯"])
    if model == ":rainbow[Kmeans] :large_orange_diamond:":
        number = int(st.sidebar.number_input("è¾“å…¥ä½ æƒ³è¦çš„èšç±»ç°‡æ•°"))
        # è¯»å–CSVæ–‡ä»¶å¹¶æ˜¾ç¤ºä¸ºDataFrame
        if number:
            with tab1:
                df = pd.read_csv(uploaded_file,encoding='gbk')
                st.dataframe(df,width=900)
            with tab2:
                process1_df =  process_df(df)
                st.dataframe(process1_df ,width=900)
            with tab3:
                process2_df = merge_lists_to_string(process1_df)
                cluster_result,x,y = Kmeans_Text_Classify(df, number)
                st.dataframe(cluster_result, width = 900)
            process_plot(x,y)
    elif model == "***DBSCAN*** :large_orange_diamond:":
        # è¯»å–CSVæ–‡ä»¶å¹¶æ˜¾ç¤ºä¸ºDataFrame
        with tab1:
            df = pd.read_csv(uploaded_file,encoding='utf-8')
            st.dataframe(df,width=900)
        with tab2:
            process1_df =  process_df(df)
            st.dataframe(process1_df ,width=900)
        with tab3:
            process2_df = merge_lists_to_string(process1_df)
            cluster_result,x,y = DBSCAN_Text_Classify(df, 3)
            st.dataframe(cluster_result, width = 900)
        process_plot(x,y)
    else:
        number = int(st.sidebar.number_input("è¾“å…¥ä½ æƒ³è¦çš„èšç±»ç°‡æ•°"))
        # è¯»å–CSVæ–‡ä»¶å¹¶æ˜¾ç¤ºä¸ºDataFrame
        if number:
            with tab1:
                df = pd.read_csv(uploaded_file,encoding='gbk')
                st.dataframe(df,width=900)
            with tab2:
                process1_df =  process_df(df)
                st.dataframe(process1_df ,width=900)
            with tab3:
                process2_df = merge_lists_to_string(process1_df)
                cluster_result,x,y = Birch_Text_Classify(df, number)
                st.dataframe(cluster_result, width = 900)
            process_plot(x,y)
        